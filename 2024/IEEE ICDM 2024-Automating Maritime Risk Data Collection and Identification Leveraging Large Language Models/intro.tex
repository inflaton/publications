\section{Introduction}
%\subsection{Background and Motivation}

The collection and analysis of risk or anomaly data from online news sources are critical for effective risk management~\cite{wang2013understanding, wang2014anomaly}. Maritime risk management and research are especially essential. However, traditional methods for gathering and categorizing such data are often labor-intensive, time-consuming, and expensive~\cite{babelsenticnet,blending,camsta,ngulea}. Existing approaches rely heavily on manual effort for data labeling and annotation, which not only incurs significant operational costs but also limits scalability. For instance, using services like NewsAPI for comprehensive data collection can be prohibitively expensive\footnote{News API Pricing: \url{https://newsapi.ai/plans}}, with search volumes insufficient to meet the needs of advanced risk information analytics.

Recent advancements in machine learning (ML) and natural language processing (NLP) have begun to address these challenges by automating parts of the data collection and classification pipeline~\cite{nlu,7pillars,hu2023msrl,primenet,wang2023learning, jiisui,hu2021stock}. 

Specifically:
\begin{itemize}
    \item Teske et al. proposed a two-step NLP pipeline using traditional ML models like Logistic Regression and AdaBoost to classify maritime incident articles and extract relevant information\cite{teske2018automatic}.
    
    \item Jidkov et al. further enhanced this approach using deep learning techniques such as convolutional neural networks (CNNs) to identify specific types of incidents, although their models faced challenges like overfitting due to limited training data\cite{jidkov2020enabling}.
    
    \item Subsequent research by Mackenzie et al.  introduced advanced metadata extraction techniques using models like CatBoost to improve the accuracy of information retrieval from unstructured news articles\cite{mackenzie2021maritime}.
\end{itemize}

While these traditional ML and deep learning models have shown promise, they are often limited by the quality and volume of labeled data available for training. The emergence of Large Language Models (LLMs) like GPT-3 and its successors has marked a significant shift in NLP capabilities. LLMs such as OpenAI's GPT-4o can perform a wide range of NLP tasks, including text classification, summarization, and entity extraction, using few-shot learning---a technique that requires only a few examples to achieve high performance. Brown et al. demonstrated that scaling up language models improves their adaptability to new and diverse input data, which is crucial for maritime risk assessment models where real-time data is heterogeneous and constantly evolving\cite{brown2020language}.

Building on these advancements, this paper presents a novel pipeline that leverages LLMs to automate the collection and categorization of global incident news. Our approach integrates traditional ML models and state-of-the-art LLMs, such as GPT-4o, to evaluate their effectiveness in news classification tasks. We find that LLMs, particularly GPT-4o, consistently outperform traditional models, enhancing both the efficiency and accuracy of maritime risk data collection. The proposed pipeline not only streamlines the categorization process but also ensures the timely delivery of relevant insights, which is vital for proactive risk management.\\

This study contributes to the growing body of literature on the application of LLMs in risk management by demonstrating their superiority over traditional models in handling complex, real-world datasets. We also introduce a new evaluation metric, the ``Ratio of Valid Categories,'' to measure the reliability of model outputs in classification tasks. This metric provides deeper insights into the performance of various models, highlighting the importance of model robustness and data quality in automated data collection pipelines.

%\subsection{Contributions}
Our main contributions are:
\begin{itemize}
    \item Develop a new method for automated maritime risk data collection and identification.
    \item Propose a new evaluation metric: Ratio of Valid Categories ($RVC$).
    \item Analyze and compare the capabilities of the proposed method with traditional ML models and LLMs for maritime risk identification from news.
    \item Demonstrate the merits of the proposed method with LLMs in maritime risk data collection and identification across different evaluation methods.
\end{itemize}

% \section{Introduction}
% \subsection{Background and Motivation}

% The collection and analysis of maritime risk data from online news sources are critical for effective risk management and research. However, traditional methods for gathering and categorizing such data are often labor-intensive, time-consuming, and expensive. Existing approaches rely heavily on manual effort for data labeling and annotation, which not only incurs significant operational costs but also limits scalability. For instance, using services like NewsAPI for comprehensive data collection can be prohibitively expensive\footnote{News API Pricing: \url{https://newsapi.ai/plans}}, with search volumes insufficient to meet the needs of advanced risk information analytics.

% Recent advancements in machine learning (ML) and natural language processing (NLP) have begun to address these challenges by automating parts of the data collection and classification pipeline. Teske et al. proposed a two-step NLP pipeline using traditional ML models like Logistic Regression and AdaBoost to classify maritime incident articles and extract relevant information. Jidkov et al.  further enhanced this approach using deep learning techniques such as convolutional neural networks (CNNs) to identify specific types of incidents, although their models faced challenges like overfitting due to limited training data. Subsequent research by Mackenzie et al.  introduced advanced metadata extraction techniques using models like CatBoost to improve the accuracy of information retrieval from unstructured news articles.

% While these traditional ML and deep learning models have shown promise, they are often limited by the quality and volume of labeled data available for training. The emergence of Large Language Models (LLMs) like GPT-3 and its successors has marked a significant shift in NLP capabilities. LLMs such as OpenAI’s GPT-4o can perform a wide range of NLP tasks, including text classification, summarization, and entity extraction, using few-shot learning—a technique that requires only a few examples to achieve high performance. Brown et al.  demonstrated that scaling up language models improves their adaptability to new and diverse input data, which is crucial for maritime risk assessment models where real-time data is heterogeneous and constantly evolving.

% Building on these advancements, this paper presents a novel pipeline that leverages LLMs to automate the collection and categorization of global incident news. Our approach integrates traditional ML models and state-of-the-art LLMs, such as GPT-4o, to evaluate their effectiveness in news classification tasks. We find that LLMs, particularly GPT-4o, consistently outperform traditional models, enhancing both the efficiency and accuracy of maritime risk data collection. The proposed pipeline not only streamlines the categorization process but also ensures the timely delivery of relevant insights, which is vital for proactive risk management.

% This study contributes to the growing body of literature on the application of LLMs in risk management by demonstrating their superiority over traditional models in handling complex, real-world datasets. We also introduce a new evaluation metric, the "Ratio of Valid Categories," to measure the reliability of model outputs in classification tasks. This metric provides deeper insights into the performance of various models, highlighting the importance of model robustness and data quality in automated data collection pipelines.

% In summary, our work aims to enhance the efficiency of maritime risk management by automating data collection and categorization processes using advanced NLP models. The findings underscore the potential of LLMs to transform risk assessment practices, reducing the need for manual labor and improving the accuracy and reliability of incident data analysis.

% \subsection{Contributions}
% Our main contributions are:
% \begin{itemize}
%     \item Development of an automated pipeline for maritime risk data collection and categorization
%     \item Comparative analysis of traditional ML models and LLMs in maritime news classification
%     \item Introduction of a new metric: Ratio of Valid Categories (RVC)
%     \item Demonstration of LLMs' superior performance in maritime risk data processing
% \end{itemize}




% The task of collecting online news reports for event monitoring often involves time-intensive processes, leading researchers to spend a disproportionate amount of time on data management rather than on critical analysis. A study conducted in 2020 by Spasic et al\cite{spasic2020clinical}. highlighted that, while using text data to classify clinical narratives, data collection emerged as the most significant challenge. The researchers found that extensive manual labor was required, resulting in poor data utilization, where only a portion of the collected data could be effectively used for machine learning models. Additionally, the process of labeling and annotating text data demands substantial human effort, with annotators meticulously tagging each document with relevant metadata. Although this human-driven approach ensures high-quality labeled data, it also imposes significant operational overhead and hinders the scalability of data collection efforts. 
% For example, using services like newsapi.ai for comprehensive data collection can be prohibitively expensive. While 200,000 searches per month cost around \$1,300\footnote{News API Pricing: \url{https://newsapi.ai/plans}}, this search volume is insufficient for conducting advanced risk information analytics.
% This highlights the significant financial and labor-related costs associated with traditional news data collection methods.

% Given these challenges, there is a clear need for innovative approaches to incident monitoring and risk management and research, particularly those that can streamline the data collection process. Advances in Large Language Models (LLMs) present an opportunity to develop more efficient classification models and data collection pipelines, enabling researchers to better harness the vast amount of information available in the digital space. This paper focuses on improving the data collection process for news articles, specifically those related to incidents and disasters worldwide. We will explore the design, implementation, and evaluation of traditional classification models and the recent breakthroughs in Large Language Models, comparing their performance in news classification tasks. Our goal is to provide insights into optimizing these systems to support in-depth research and analysis in risk management and studies.