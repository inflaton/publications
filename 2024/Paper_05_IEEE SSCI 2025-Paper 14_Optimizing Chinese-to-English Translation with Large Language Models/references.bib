@book{koehn2009statistical,
  title={Statistical machine translation},
  author={Koehn, Philipp},
  year={2009},
  publisher={Cambridge University Press}
}

@article{sutskever2014sequence,
  title={Sequence to Sequence Learning with Neural Networks},
  author={Sutskever, I},
  journal={arXiv preprint arXiv:1409.3215},
  year={2014}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
  pages={4171--4186},
  year={2018}
}

@article{brown2020language,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{liu2020multilingual,
  title={Multilingual denoising pre-training for neural machine translation},
  author={Liu, Y},
  journal={arXiv preprint arXiv:2001.08210},
  year={2020}
}

@inproceedings{conneau2020unsupervised,
  title     = {Unsupervised Cross-lingual Representation Learning at Scale},
  author    = {Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm\'{a}n, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  year      = {2020},
  pages     = {8440--8451},
  publisher = {Association for Computational Linguistics},
  doi       = {10.18653/v1/2020.acl-main.747},
  url       = {https://aclanthology.org/2020.acl-main.747},
  address   = {Online}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@inproceedings{koehn2007moses,
  title={Moses: Open source toolkit for statistical machine translation},
  author={Koehn, Philipp and Hoang, Hieu and Birch, Alexandra and Callison-Burch, Chris and Federico, Marcello and Bertoldi, Nicola and Cowan, Brooke and Shen, Wade and Moran, Christine and Zens, Richard and others},
  booktitle={Proceedings of the 45th annual meeting of the association for computational linguistics companion volume proceedings of the demo and poster sessions},
  pages={177--180},
  year={2007},
  organization={Association for Computational Linguistics}
}

@inproceedings{zhang2007chinese,
  title     = {Chinese Word Segmentation as Character Tagging},
  author    = {Zhang, Yue and Clark, Stephen},
  booktitle = {Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics},
  year      = {2007},
  pages     = {921--928},
  publisher = {Association for Computational Linguistics},
  address   = {Prague, Czech Republic},
  url       = {https://aclanthology.org/P07-1116}
}

@article{zhang2017improving,
  title     = {Improving Chinese to English Neural Machine Translation with Linguistic Tags},
  author    = {Zhang, Biao and Xiong, Deyi and Liu, Jinsong},
  journal   = {The Prague Bulletin of Mathematical Linguistics},
  volume    = {108},
  pages     = {233--244},
  year      = {2017},
  publisher = {Charles University in Prague, Faculty of Mathematics and Physics},
  doi       = {10.1515/pralin-2017-0023},
  url       = {https://ufal.mff.cuni.cz/pbml/108/art-zhang-xiong-liu.pdf}
}

@inproceedings{zhang2018accelerating,
  title     = {Accelerating Neural Transformer Based Machine Translation with an Efficient Attention Mechanism},
  author    = {Zhang, Hao and Zhou, Mingbo and Zong, Chengqing},
  booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages     = {1791--1796},
  year      = {2018},
  publisher = {Association for Computational Linguistics},
  address   = {Brussels, Belgium},
  doi       = {10.18653/v1/D18-1202},
  url       = {https://aclanthology.org/D18-1202}
}

@article{fan2021beyond,
  title={Beyond english-centric multilingual machine translation},
  author={Fan, Angela and Bhosale, Shruti and Schwenk, Holger and Ma, Zhiyi and El-Kishky, Ahmed and Goyal, Siddharth and Baines, Mandeep and Celebi, Onur and Wenzek, Guillaume and Chaudhary, Vishrav and others},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={107},
  pages={1--48},
  year={2021}
}

@inproceedings{zhang2023machine,
  title={Machine translation with large language models: Prompting, few-shot learning, and fine-tuning with QLoRA},
  author={Zhang, Xuan and Rajabi, Navid and Duh, Kevin and Koehn, Philipp},
  booktitle={Proceedings of the Eighth Conference on Machine Translation},
  pages={468--481},
  year={2023}
}

@inproceedings{zhang2023prompting,
  title={Prompting large language model for machine translation: A case study},
  author={Zhang, Biao and Haddow, Barry and Birch, Alexandra},
  booktitle={International Conference on Machine Learning},
  pages={41092--41110},
  year={2023},
  organization={PMLR}
}

@inproceedings{freitag2022results,
  title={Results of WMT22 metrics shared task: Stop using BLEU--neural metrics are better and more robust},
  author={Freitag, Markus and Rei, Ricardo and Mathur, Nitika and Lo, Chi-kiu and Stewart, Craig and Avramidis, Eleftherios and Kocmi, Tom and Foster, George and Lavie, Alon and Martins, Andr{\'e} FT},
  booktitle={Proceedings of the Seventh Conference on Machine Translation (WMT)},
  pages={46--68},
  year={2022}
}

@inproceedings{wolf2020transformers,
  title={Transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  booktitle={Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations},
  pages={38--45},
  year={2020}
}

@inproceedings{rei2022comet,
  title={COMET-22: Unbabel-IST 2022 submission for the metrics shared task},
  author={Rei, Ricardo and De Souza, Jos{\'e} GC and Alves, Duarte and Zerva, Chrysoula and Farinha, Ana C and Glushkova, Taisiya and Lavie, Alon and Coheur, Luisa and Martins, Andr{\'e} FT},
  booktitle={Proceedings of the Seventh Conference on Machine Translation (WMT)},
  pages={578--585},
  year={2022}
}

@inproceedings{zheng2024llamafactory,
  title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models},
  author={Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Zhangchi Feng and Yongqiang Ma},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
  address={Bangkok, Thailand},
  publisher={Association for Computational Linguistics},
  year={2024},
  url={http://arxiv.org/abs/2403.13372}
}

@article{hu2021lora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{dettmers2023qlora,
  title={QLoRA: Efficient Finetuning of Quantized LLMs},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2305.14314},
  year={2023}
}

@inproceedings{huang2024performance,
  title={Performance Analysis of Llama 2 Among Other LLMs},
  author={Huang, Donghao and Hu, Zhenda and Wang, Zhaoxia},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)},
  pages={1081--1085},
  year={2024},
  organization={IEEE}
}

@inproceedings{huang2024evaluation,
  title={Evaluation of orca 2 against other llms for retrieval augmented generation},
  author={Huang, Donghao and Wang, Zhaoxia},
  booktitle={Pacific-Asia Conference on Knowledge Discovery and Data Mining},
  pages={3--19},
  year={2024},
  organization={Springer}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{huang2024automating,
  author    = {Donghao Huang and Xiuju Fu and Xiaofeng Yin and Haibo Pen and Zhaoxia Wang},
  title     = {Automating Maritime Risk Data Collection and Identification Leveraging Large Language Models},
  booktitle = {2024 IEEE International Conference on Data Mining Workshops (ICDMW)},
  pages     = {433--439},
  year      = {2024},
  organization = {IEEE},
}